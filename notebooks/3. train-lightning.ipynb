{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ik0iJ9Rxj0Gm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import ir_datasets\n",
    "\n",
    "import math\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "import gzip\n",
    "import csv\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Iterable, Type, Union, Callable\n",
    "\n",
    "import transformers\n",
    "from sentence_transformers import models, losses, datasets\n",
    "from sentence_transformers import LoggingHandler, SentenceTransformer, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator, SentenceEvaluator \n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor, device\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from fastcore.basics import store_attr\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "seed = 0\n",
    "seed_everything(seed, workers=True)\n",
    "\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_text</th>\n",
       "      <th>doc_text</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does Quora look to a moderator?</td>\n",
       "      <td>What does the Quora website look like to membe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I refuse to chose between different thi...</td>\n",
       "      <td>Is it possible to pursue many different things...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did Ben Affleck shine more than Christian Bale...</td>\n",
       "      <td>According to you, whose Batman performance was...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did Ben Affleck shine more than Christian Bale...</td>\n",
       "      <td>No fanboys please, but who was the true batman...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Did Ben Affleck shine more than Christian Bale...</td>\n",
       "      <td>Who do you think portrayed Batman better: Chri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          query_text  \\\n",
       "0                How does Quora look to a moderator?   \n",
       "1  How do I refuse to chose between different thi...   \n",
       "2  Did Ben Affleck shine more than Christian Bale...   \n",
       "3  Did Ben Affleck shine more than Christian Bale...   \n",
       "4  Did Ben Affleck shine more than Christian Bale...   \n",
       "\n",
       "                                            doc_text  relevance  \n",
       "0  What does the Quora website look like to membe...          1  \n",
       "1  Is it possible to pursue many different things...          1  \n",
       "2  According to you, whose Batman performance was...          1  \n",
       "3  No fanboys please, but who was the true batman...          1  \n",
       "4  Who do you think portrayed Batman better: Chri...          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = config.DATASET\n",
    "save_path = Path(f\"data/{dataset_name}\")\n",
    "df = pd.read_pickle(save_path/\"data.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7626\n",
       "1    7626\n",
       "Name: relevance, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.relevance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "executionInfo": {
     "elapsed": 465,
     "status": "ok",
     "timestamp": 1622960820208,
     "user": {
      "displayName": "Pratik Bhavsar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlU8zpRNrvsulni8P4zzsD1TFpmA3QoAMVIOlZwA=s64",
      "userId": "06219224739467266869"
     },
     "user_tz": -330
    },
    "id": "xki-ddd7-jny",
    "outputId": "f04391e9-3351-414c-ccef-eed8896d1157"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15252\n",
      "12201 3051\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_text</th>\n",
       "      <th>doc_text</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2289</th>\n",
       "      <td>What are the factors that can make your credit...</td>\n",
       "      <td>What are the best ways to learn Cloud Computing?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6499</th>\n",
       "      <td>What is a fun board game to play with only 2 p...</td>\n",
       "      <td>Why don't we have fusion reactors in power sta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3620</th>\n",
       "      <td>Which business/startup should I start in Nagpu...</td>\n",
       "      <td>Which is the best business to start in nagpur?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>Why are most airliners painted white?</td>\n",
       "      <td>Why are Aeroplanes painted white?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>What are the top MBA colleges in the world?</td>\n",
       "      <td>Do you believe in free will or determinism?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             query_text  \\\n",
       "2289  What are the factors that can make your credit...   \n",
       "6499  What is a fun board game to play with only 2 p...   \n",
       "3620  Which business/startup should I start in Nagpu...   \n",
       "2375              Why are most airliners painted white?   \n",
       "1383        What are the top MBA colleges in the world?   \n",
       "\n",
       "                                               doc_text  relevance  \n",
       "2289   What are the best ways to learn Cloud Computing?          0  \n",
       "6499  Why don't we have fusion reactors in power sta...          0  \n",
       "3620     Which is the best business to start in nagpur?          1  \n",
       "2375                  Why are Aeroplanes painted white?          1  \n",
       "1383        Do you believe in free will or determinism?          0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "\n",
    "print(len(df))\n",
    "df_train, df_val = train_test_split(df, train_size=train_size, stratify=df.relevance, random_state=seed)\n",
    "print(len(df_train), len(df_val))\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<InputExample> label: 0, texts: What are the factors that can make your credit score drop?; What are the best ways to learn Cloud Computing?\n"
     ]
    }
   ],
   "source": [
    "train_samples = []\n",
    "for row in df_train.itertuples():\n",
    "    train_samples.append(InputExample(texts=[row.query_text, row.doc_text], label=row.relevance))\n",
    "\n",
    "test_samples = []\n",
    "for row in df_val.itertuples():\n",
    "    test_samples.append(InputExample(texts=[row.query_text, row.doc_text], label=row.relevance))\n",
    "\n",
    "print(test_samples[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McmZsPE3-H-X"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TQVVRH-GD5ca"
   },
   "outputs": [],
   "source": [
    "model_name = config.MODEL\n",
    "train_batch_size = 128  #The larger you select this, the better the results (usually). But it requires more GPU memory\n",
    "val_batch_size = 128\n",
    "max_seq_length = 128\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "C-qg3IBiGwoZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paraphrase-mpnet-base-v2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = config.MODEL\n",
    "model = SentenceTransformer(model_name)\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "71eLlooq8JO9"
   },
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_batch_size=32, val_batch_size=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.val_batch_size = val_batch_size\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.train_data = train_samples\n",
    "        self.val_data = test_samples\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        pass\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataloader = datasets.NoDuplicatesDataLoader(self.train_data, batch_size=self.train_batch_size)\n",
    "        return train_dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataloader = datasets.NoDuplicatesDataLoader(self.val_data, batch_size=self.val_batch_size)\n",
    "        return val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "tTo2Cc6aEBb3"
   },
   "outputs": [],
   "source": [
    "class SentenceTransformerModel(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                loss_model,\n",
    "                max_seq_length: int = 128,\n",
    "                evaluator: SentenceEvaluator = None,\n",
    "                epochs: int = 1,\n",
    "                steps_per_epoch = None,\n",
    "                scheduler: str = 'WarmupLinear',\n",
    "                warmup_steps: int = 10000,\n",
    "                optimizer_class: Type[Optimizer] = transformers.AdamW,\n",
    "                optimizer_params : Dict[str, object]= {'lr': 2e-5},\n",
    "                weight_decay: float = 0.01,\n",
    "                ):\n",
    "        \n",
    "        super(SentenceTransformerModel, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        store_attr(\"loss_model, epochs, weight_decay, optimizer_class, optimizer_params, steps_per_epoch, scheduler, warmup_steps\")\n",
    "        self.loss_model.max_seq_length = max_seq_length\n",
    "    \n",
    "#     def on_epoch_start(self):\n",
    "#         print('\\n')\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        loss = self.loss_model(features, labels)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, data, batch_idx):\n",
    "        features, labels = self.loss_model.model.smart_batching_collate(data)\n",
    "        loss = self.forward(features, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, data, batch_idx):\n",
    "        #TODO: dev_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, batch_size=train_batch_size, name='sts-dev')\n",
    "        features, labels = self.loss_model.model.smart_batching_collate(data)\n",
    "        loss = self.forward(features, labels)\n",
    "        # _, preds = torch.max(logits, dim=1)\n",
    "        # val_acc = accuracy_score(preds.cpu(), batch[\"label\"].cpu())\n",
    "        # val_acc = torch.tensor(val_acc)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        # self.log(\"val_acc\", val_acc, prog_bar=True)\n",
    "#         return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # return torch.optim.Adam(self.parameters(), lr=self.hparams[\"lr\"])\n",
    "        param_optimizer = list(self.loss_model.named_parameters())\n",
    "\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': self.weight_decay},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "\n",
    "        optimizer = self.optimizer_class(optimizer_grouped_parameters, **self.optimizer_params)\n",
    "        \n",
    "#         if self.steps_per_epoch is None or self.steps_per_epoch == 0:\n",
    "#             self.steps_per_epoch = min([len(dataloader) for dataloader in dataloaders])\n",
    "\n",
    "#         num_train_steps = int(self.steps_per_epoch * self.epochs)\n",
    "#         scheduler_obj = self.loss_model.model._get_scheduler(optimizer, scheduler=self.scheduler, warmup_steps=self.warmup_steps, t_total=num_train_steps)\n",
    "\n",
    "#         return [[optimizer], [scheduler_obj]]\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ProgressBar, ModelCheckpoint\n",
    "\n",
    "class LitProgressBar(ProgressBar):\n",
    "    def on_train_epoch_end(self, *args, **kwargs):\n",
    "        super().on_train_epoch_end(*args, **kwargs)\n",
    "        print()\n",
    "        \n",
    "checkpoint_callback = ModelCheckpoint(dirpath=\"./models\", monitor=\"val_loss\", mode=\"min\")\n",
    "early_stop_callback = EarlyStopping(monitor='val_loss', min_delta=0.00, patience=5, verbose=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger = WandbLogger(project=\"lightning-sentence-transformers\", name=\"test\", reinit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "w_ckceLKb8Lx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Using native 16bit precision.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpratik\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.32<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">test</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/pratik/lightning-sentence-transformers\" target=\"_blank\">https://wandb.ai/pratik/lightning-sentence-transformers</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/pratik/lightning-sentence-transformers/runs/11zj6etf\" target=\"_blank\">https://wandb.ai/pratik/lightning-sentence-transformers/runs/11zj6etf</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\prati\\Documents\\GitHub\\semantic-search\\notebooks\\wandb\\run-20210620_211447-11zj6etf</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name       | Type                         | Params\n",
      "------------------------------------------------------------\n",
      "0 | loss_model | MultipleNegativesRankingLoss | 109 M \n",
      "------------------------------------------------------------\n",
      "109 M     Trainable params\n",
      "0         Non-trainable params\n",
      "109 M     Total params\n",
      "437.946   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b5db88122d474eb46107c8c0900018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pl_data = DataModule()\n",
    "loss_model = losses.MultipleNegativesRankingLoss(model)\n",
    "steps_per_epoch = 476\n",
    "stl_model = SentenceTransformerModel(loss_model, steps_per_epoch=steps_per_epoch,)\n",
    "\n",
    "#TODO: Add learning rate scheduler\n",
    "trainer = pl.Trainer(\n",
    "    default_root_dir=\"logs\",\n",
    "    gpus=(1 if torch.cuda.is_available() else 0),\n",
    "    max_epochs=10,\n",
    "    fast_dev_run=False,\n",
    "    gradient_clip_val=1.0,\n",
    "    amp_backend='native',\n",
    "    amp_level='O2',\n",
    "    precision=16,\n",
    "    auto_lr_find=True,\n",
    "    auto_scale_batch_size=False,\n",
    "    auto_select_gpus=True,\n",
    "#     callbacks=[LitProgressBar()],\n",
    "#     logger=pl.loggers.TensorBoardLogger(\"logs/\", name=model_name, version=1),\n",
    "    logger=wandb_logger,\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "trainer.fit(stl_model, pl_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOyV9dmCvaqa5udL/Bo/m2/",
   "collapsed_sections": [],
   "name": "train-lightning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
